#!/usr/bin/env node
import { readFileSync } from "node:fs";
import { dirname, join } from "node:path";
import { fileURLToPath } from "node:url";
import { Command } from "commander";
import chalk from "chalk";
import type { Provider } from "./config.js";
import { parseConfig } from "./config.js";
import { runMultipleTests } from "./client.js";
import { calculateMetrics, calculateStats } from "./metrics.js";
import { renderReport, renderSingleResult } from "./chart.js";

function getCliVersion(): string {
  try {
    const currentDir = dirname(fileURLToPath(import.meta.url));
    const packagePath = join(currentDir, "..", "package.json");
    const packageJson = JSON.parse(readFileSync(packagePath, "utf-8")) as { version?: string };
    return packageJson.version ?? "unknown";
  } catch {
    return "unknown";
  }
}

const program = new Command();

program
  .name("token-speed-test")
  .description("A CLI tool to test LLM API token output speed")
  .version(getCliVersion());

program
  .option("-k, --api-key <key>", "API Key (required)", "")
  .option("-p, --provider <provider>", "API provider: anthropic or openai", "anthropic")
  .option("-u, --url <url>", "Custom API endpoint URL")
  .option("-m, --model <model>", "Model name")
  .option("--max-tokens <number>", "Maximum output tokens", "1024")
  .option("-r, --runs <number>", "Number of test runs", "3")
  .option("--prompt <text>", "Test prompt", "ÂÜô‰∏ÄÁØáÂÖ≥‰∫é AI ÁöÑÁü≠Êñá")
  .parse(process.argv);

const options = program.opts();

async function main() {
  try {
    // Ëß£ÊûêÈÖçÁΩÆ
    const config = parseConfig({
      apiKey: options.apiKey,
      provider: options.provider as Provider,
      url: options.url,
      model: options.model,
      maxTokens: parseInt(options.maxTokens, 10),
      runs: parseInt(options.runs, 10),
      prompt: options.prompt,
    });

    // ÊòæÁ§∫ÈÖçÁΩÆ‰ø°ÊÅØ
    console.log(chalk.cyan("\nüöÄ Token ÈÄüÂ∫¶ÊµãËØïÂ∑•ÂÖ∑"));
    console.log(chalk.gray("‚îÄ".repeat(50)));
    console.log(chalk.gray(`Provider: ${chalk.white(config.provider)}`));
    console.log(chalk.gray(`Model: ${chalk.white(config.model)}`));
    console.log(chalk.gray(`Max Tokens: ${chalk.white(config.maxTokens)}`));
    console.log(chalk.gray(`Runs: ${chalk.white(config.runCount)}`));
    console.log(
      chalk.gray(
        `Prompt: ${chalk.white(config.prompt.substring(0, 50))}${config.prompt.length > 50 ? "..." : ""}`
      )
    );
    console.log(chalk.gray("‚îÄ".repeat(50)));

    // ÊâßË°åÊµãËØï
    console.log(chalk.yellow("\n‚è≥ Ê≠£Âú®ËøêË°åÊµãËØï...\n"));
    console.log(chalk.gray("Ê®°ÂûãËæìÂá∫ (ÊµÅÂºè):\n"));

    const results = await runMultipleTests(config);

    // ËÆ°ÁÆóÊåáÊ†á
    const allMetrics = results.map((r) => calculateMetrics(r));

    // ÊòæÁ§∫ÊØèÊ¨°ËøêË°åÁöÑÁªìÊûú
    for (let i = 0; i < allMetrics.length; i++) {
      console.log(chalk.gray(renderSingleResult(allMetrics[i], i)));
    }

    // ËÆ°ÁÆóÁªüËÆ°
    const stats = calculateStats(allMetrics);

    // ÊòæÁ§∫Êä•Âëä
    console.log(chalk.cyan("\n" + renderReport(stats)));

    console.log(chalk.green("\n‚úÖ ÊµãËØïÂÆåÊàê!\n"));
  } catch (error) {
    if (error instanceof Error) {
      console.error(chalk.red(`\n‚ùå ÈîôËØØ: ${error.message}\n`));
    } else {
      console.error(chalk.red("\n‚ùå ÂèëÁîüÊú™Áü•ÈîôËØØ\n"));
    }
    process.exit(1);
  }
}

void main();
